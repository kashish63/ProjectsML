{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset for this Project:**\n",
        "https://drive.google.com/file/d/1pQxtljlNVh0DHYg-Ye7dtpDTlFceHVfa/view"
      ],
      "metadata": {
        "id": "zzpQDCNKkG2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Dependencies**\n"
      ],
      "metadata": {
        "id": "i3z5O8PRSTFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ki37TeMLFdV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection and Data Preprocessing**\n",
        "\n",
        "Data Collection leads to collect data for training and testing purpose\n",
        "\n",
        "Data preprocessing transforms the data into a format that is more easily and effectively processed in machine learning tasks. "
      ],
      "metadata": {
        "id": "Wlbv5k57SsUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transferring a dataset to a pandas dataframe to provide easierÂ access to the data\n",
        "sonar_data = pd.read_csv('/content/sonar data.csv', header=None)\n",
        "\n",
        "#printing the first five rows of the data\n",
        "sonar_data.head()"
      ],
      "metadata": {
        "id": "IFr18-rcHYBB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4d1431b6-372d-4d2f-f8ee-08817def1e33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   R  \n",
              "1  0.0052  0.0044   R  \n",
              "2  0.0095  0.0078   R  \n",
              "3  0.0040  0.0117   R  \n",
              "4  0.0107  0.0094   R  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f57500c5-89d6-4a83-a86a-76d2dd268099\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f57500c5-89d6-4a83-a86a-76d2dd268099')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f57500c5-89d6-4a83-a86a-76d2dd268099 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f57500c5-89d6-4a83-a86a-76d2dd268099');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Separating data and labels**\n",
        "\n",
        "X: Add all of the Data's features to the X variable. To accomplish this, we must remove the label column from the data and store the remaining columns as X variables. We can remove label column from the data by using the panda's drop function. This function takes the name of the column you wish to remove and the axis. Axis 0 leads to dropping rows, while axis 1 drops columns.\n",
        "\n",
        "Y: Store label of the data to the variable Y"
      ],
      "metadata": {
        "id": "EI7HBm2rTBgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=sonar_data.drop(columns=60, axis=1)\n",
        "Y=sonar_data[60]\n",
        "\n",
        "#print X data\n",
        "print(X)\n",
        "\n",
        "#print Y data\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "Cllt5JQaJQPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afea2910-d5a9-4300-aec9-6594d94d6bc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0       1       2       3       4       5       6       7       8   \\\n",
            "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
            "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
            "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
            "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
            "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
            "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
            "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
            "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
            "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
            "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
            "\n",
            "         9   ...      50      51      52      53      54      55      56  \\\n",
            "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
            "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
            "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
            "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
            "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
            "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
            "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
            "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
            "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
            "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
            "\n",
            "         57      58      59  \n",
            "0    0.0084  0.0090  0.0032  \n",
            "1    0.0049  0.0052  0.0044  \n",
            "2    0.0164  0.0095  0.0078  \n",
            "3    0.0044  0.0040  0.0117  \n",
            "4    0.0048  0.0107  0.0094  \n",
            "..      ...     ...     ...  \n",
            "203  0.0115  0.0193  0.0157  \n",
            "204  0.0032  0.0062  0.0067  \n",
            "205  0.0138  0.0077  0.0031  \n",
            "206  0.0079  0.0036  0.0048  \n",
            "207  0.0036  0.0061  0.0115  \n",
            "\n",
            "[208 rows x 60 columns]\n",
            "0      R\n",
            "1      R\n",
            "2      R\n",
            "3      R\n",
            "4      R\n",
            "      ..\n",
            "203    M\n",
            "204    M\n",
            "205    M\n",
            "206    M\n",
            "207    M\n",
            "Name: 60, Length: 208, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting Data into Training data and Testing data**\n",
        "\n",
        "**Train Test Split:** Split arrays or matrices into random train and test subsets.\n",
        "\n",
        "Spliting data into four variables X_train, X_text, Y_train, Y_test\n",
        "\n",
        "The X_train variable will hold all of the training data, and the Y_train variable will have the label of the X_tarin data.\n",
        "\n",
        "Data for evoluation will be store in the X_test label of X_test data will store in the Y_test variable.\n",
        "\n",
        "---\n",
        "\n",
        "**test-size:** it defines the ratio of data which divide into traning and testing data.\n",
        "\n",
        "0.1 = 10% data for testing and rest 90% data for traning\n",
        "\n",
        "0.2 = 20% data for testing and rest 80% data for traning\n",
        "\n",
        "---\n",
        "\n",
        "**Stratify:**  This will be used by the train_test_split() function to ensure that both the train and test sets have the proportion of examples in each class that is present in the provided âyâ array.Like in this model we use Stratify = Y as it divide equal 1 and 0 to the train and test data\n",
        "\n",
        "**Random State:** The random state hyperparameter in the train_test_split() function controls the shuffling process. With random_state=None , we get different train and test sets across different executions and the shuffling process is out of control. With random_state=0 or 1 or 2, we get the same train and test sets across different executions.\n"
      ],
      "metadata": {
        "id": "wDs6HPKxTJac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=1)\n",
        "\n",
        "\n",
        "#printing number of rows and columns of X, X_train and X_test\n",
        "\n",
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "znR-_9dgKOKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c096d91-55ff-4d11-ded0-9be178c4b204"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 60) (187, 60) (21, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression in Machine Learning**\n",
        "\n",
        "Logistic regression is one of the most popular Machine Learning algorithms, which comes under the Supervised Learning technique. It is used for predicting the categorical dependent variable using a given set of independent variables. Logistic regression is used for solving the classification problems.\n",
        "\n",
        "Logistic regression predicts the output of a categorical dependent variable. Therefore the outcome must be a categorical or discrete value. It can be either Yes or No, 0 or 1, true or False, etc. but instead of giving the exact value as 0 and 1, it gives the probabilistic values which lie between 0 and 1.\n",
        "\n",
        "In Logistic regression, instead of fitting a regression line, we fit an \"S\" shaped logistic function, which predicts two maximum values (0 or 1).\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "S59zJP9gpNU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train using Logistic Regression** "
      ],
      "metadata": {
        "id": "5ZvPgDZCTRld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression()\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "ydqCGoBgL7nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "9d5e51d9-1532-44eb-8c7d-12719fbc9aa8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation:** Model evaluation is the process of using different evaluation metrics to understand a machine learning model's performance, as well as its strengths and weaknesses.\n",
        "\n",
        "**Accuracy score:** A function imported from sklearn.metrics. Accuracy score in machine learning is an evaluation metric that measures the number of correct predictions made by a model in relation to the total number of predictions made. We calculate it by dividing the number of correct predictions by the total number of predictions."
      ],
      "metadata": {
        "id": "hVk5LBNWNX-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy score between 70 to 80 leads to a good model\n",
        "\n",
        "#Accuracy Score on Training Data\n",
        "\n",
        "#predict the Result in 0 and 1 form\n",
        "X_train_prediction = model.predict(X_train)\n",
        "\n",
        "#Now compare it with original label i.e Y_train\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "\n",
        "#Print Accuracy Score on Training Data  \n",
        "print('Accuracy Score on Training Data: ', training_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIt0yOYLMc2P",
        "outputId": "738f2bbd-f231-4fab-af3e-673d90334d0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on Training Data:  0.8342245989304813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy score on Test data\n",
        "\n",
        "#predict the Result in 0 and 1 form\n",
        "X_test_prediction = model.predict(X_test)\n",
        "\n",
        "#Now compare it with original label i.e Y_train \n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "\n",
        "#Print Accuracy score on Test data\n",
        "print('Accuracy score on Test data: ', test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ku74yGIOXhq",
        "outputId": "409f22e0-a572-4563-d921-45da9d95c113"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on Test data:  0.7619047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is working very well as it is giving 76% accuracy on test data "
      ],
      "metadata": {
        "id": "i3R9miDixEV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making a Predictive System**"
      ],
      "metadata": {
        "id": "G1Y_reolPg-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data=(0.0126,0.0519,0.0621,0.0518,0.1072,0.2587,0.2304,0.2067,0.3416,0.4284,0.3015,0.1207,0.3299,0.5707,0.6962,0.9751,1.0000,0.9293,0.6210,0.4586,0.5001,0.5032,0.7082,0.8420,0.8109,0.7690,0.8105,0.6203,0.2356,0.2595,0.6299,0.6762,0.2903,0.4393,0.8529,0.7180,0.4801,0.5856,0.4993,0.2866,0.0601,0.1167,0.2737,0.2812,0.2078,0.0660,0.0491,0.0345,0.0172,0.0287,0.0027,0.0208,0.0048,0.0199,0.0126,0.0022,0.0037,0.0034,0.0114,0.0077)\n",
        "\n",
        "#Changing the input data to numpy array\n",
        "numpy_array=np.asarray(input_data)\n",
        "\n",
        "#Reshape data as we are predicting for one instance\n",
        "reshaped=numpy_array.reshape(1,-1)\n",
        "\n",
        "prediction = model.predict(reshaped)\n",
        "\n",
        "print('Prediction: ', prediction)\n",
        "\n",
        "if(prediction[0]=='R'):\n",
        "  print('The object is Rock')\n",
        "else:\n",
        "  print('The object is Mine')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXey7-yMPOIk",
        "outputId": "6bb54a0f-b4da-482b-b438-eac9c974898b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  ['R']\n",
            "The object is Rock\n"
          ]
        }
      ]
    }
  ]
}